## Overview & Progress

- [x] Pythonの導入
  - [x] Pythonとは
  - [x] 開発環境の構築について
    - [x] ローカルにAnacondaを使って環境構築
    - [x] Google Colaboratoryで環境構築
  - [x] Pythonの基本的な使い方
    - [x] 算術演算
    - [x] 比較演算子
    - [x] データ型
    - [x] リスト
    - [x] タプル
    - [x] 辞書
    - [x] 条件分岐
    - [x] 関数定義
    - [x] ループ処理
    - [x] リスト内包表記
- [x] Pythonを使ったデータ処理
  - [x] ライブラリのインストール
  - [x] Numpyライブラリの使い方
    - [x] numpy基礎
    - [x] 要素へのアクセス
    - [x] 演算
    - [x] いろいろな初期化
  - [x] Pandasの使い方
    - [x] Series
    - [x] DataFrame
    - [x] 便利なメソッド
    - [x] データの読み込み
  - [x] Pythonの可視化ライブラリ
    - [x] ヒストグラム
    - [x] 散布図
    - [x] 折れ線グラフ
    - [x] その他
  - [x] データ分析の流れ
    - [x] データを集める
    - [x] 前処理(データ整形)
    - [x] 分析
    - [x] 評価方法
    - [x] 考察
- [x] 教師あり〜回帰〜
  - [x] 線形回帰
    - [x] 回帰分析
    - [x] 線形回帰分析のイメージ
    - [x] 重回帰分析のイメージ
    - [x] パラメータの導出
    - [x] 連続値ではない変数
    - [x] 実践編1(ボストン市内の地域別住宅価格データ)
    - [x] 実践編2(東京都の不動産価格データ)
  - [x] リッジ回帰・ラッソ回帰
    - [x] 過学習
    - [x] ラッソ回帰
    - [x] リッジ回帰
    - [x] ラッソ回帰とリッジ回帰の効果
    - [x] 実践編1(ボストン市内の地域別住宅価格データ)
    - [x] 実践編2(東京都の不動産価格データ)
- [x] 教師あり〜分類〜
  - [x] ロジスティック回帰
    - [x] 分類とは
    - [x] 線形回帰で解こうとしてみる
    - [x] ロジスティック回帰
    - [x] 実践編1(irisデータ)
    - [x] 実践編2(Tweetデータ)
  - [x] 決定木
    - [x] 決定木とは
    - [x] 不純度の考え
    - [x] 決定木と剪定
    - [x] 実践編1(irisデータ)
    - [x] 実践編2(Tweetデータ)
  - [x] ランダムフォレスト
    - [x] バギングとは
    - [x] ランダムフォレスト
    - [x] 実践編1(irisデータ)
    - [x] 実践編2(Tweetデータ)
- [x] 教師なし
  - [x] 主成分分析
    - [x] 「情報の量」と分散
    - [x] 分散を大きく圧縮する
    - [x] 実践編1(irisデータ)
    - [ ] 実践編2(都道府県ごとの家計調査データ)
  - [x] K平均法
    - [x] クラスタリング
    - [x] K平均法
    - [x] 実践編1(irisデータ)
    - [x] 実践編2(都道府県ごとの家計調査データ)
- [x] 評価指標
  - [x] 回帰における評価指標
    - [x] RMSE
    - [x] MAE
    - [x] RMSLE
    - [x] RMSE・MAEを比較
    - [x] RMSE・RMSLEを比較
    - [x] 実践編
  - [x] 分類における評価指標
    - [x] 正解率
    - [x] なぜ不均衡なクラスでの正解率評価が問題か？
    - [x] 偽陽性率と真陽性率
    - [x] ROC曲線とは
    - [x] ROC曲線をプロット
    - [x] AUCの考え方
    - [x] 実践編
- [x] ニューラルネットワーク
  - [x] ニューラルネットワーク
    - [x] 概要
    - [x] シンプルな例
    - [x] 活性化関数と損失関数
    - [x] 中間層を追加したニューラルネットワーク
    - [x] 行列による、重みの表現
    - [x] 実践編1(irisデータ)
    - [x] 実践編2(寺と神社の画像データ)
  - [x] 畳み込みニューラルネットワーク
    - [x] 通常のネットワークで画像分類
    - [x] 畳み込み層
    - [x] プーリング層
    - [x] 実践編1(mnistデータ)
    - [x] 実践編2(お寺と神社のデータ)
- [x] その他の手法
  - [x] word2vec
    - [x] word2vecとは
    - [x] 単語ベクトルを作るために必要なフェイクタスク
    - [x] 入力層・中間層・出力層のみのニューラルネットワーク
    - [x] 入力データを教師データを重み行列
    - [x] フェイクタスクの結果と単語ベクトルの関係性
    - [x] 実践編
  - [x] 協調フィルタリング
    - [x] レコメンドとは
    - [x] 協調フィルタリング
    - [x] ユーザーベース型協調フィルタリング
    - [x] 協調フィルタリングの欠点
    - [x] 実践編
- [x] 本編で省略した事項について
  - [x] 最小二乗法
  - [x] シグモイド関数
  - [x] ロジスティック回帰の損失関数

## Steps

- データを集める
- 前処理
- 分析
- 評価
- 考察

- とりあえずdataFrameに打ち込む
- データをちゃんと読む
- グラフとかにして関係をみてみる

## ざっくり用語

- 教師あり〜回帰〜
  - 訓練誤差: 学習データでの精度。
  - 汎化誤差: 未知データでの精度。
  - 過学習: 訓練誤差で評価がよく、汎化誤差で評価が悪い状態。
  - 正則化: パラメータに制約を課すこと。それにより過学習を防いだりする。
  - ラッソ回帰: L1正則化(パラメータの絶対値の和を用いた正則化)項を用いた回帰
  - リッジ回帰: L2正則化(パラメータの絶対値の二乗和を用いた正則化)項を用いた回帰
- 教師あり〜分類〜
  - シグモイド関数: 0~1に値が入るよう変換した関数。 1/(1 + e^(-(ax + b)))
  - 尤度: データを得られる確率を計算したもの
  - 最尤法: 最も尤度が高いパラメータを求める手法
  - 不純度: いろいろなクラスの混在具合。混在するほど高い。
  - バギング: ブートストラップサンプリングで得られたデータで、モデルを複数作る手法

## Memo

- Juypter Notebookで補完ってできないの...？
- JupyterLabというのがあるらしい
- VSCodeでもできるっぽい？

## Refs

- [Np-Ur/PythonBook: 「Pythonと実データで遊んで学ぶ データ分析講座」 サポートページ](https://github.com/Np-Ur/PythonBook)
